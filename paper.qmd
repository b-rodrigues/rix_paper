---
title: "Reproducible development environments with rix"
format:
    jss-pdf:
        keep-tex: true
    jss-html: default
author:
  - name: Bruno Rodrigues 
    affiliations:
      - name: Ministry of Research and Higher education, Luxembourg 
        department: Department of Statistics
        address: 18, Montée de la Pétrusse
        city: Luxembourg 
        country: Luxembourg 
        postal-code: 2327
      - Journal of Statistical Software
    orcid: 0000-0002-3211-3689
    email: bruno@brodrigues.co
    url: https://www.brodrigues.co 
  - name: Philipp Baumann
    affiliations:
      - Plus Affiliation
abstract: |
  In order to create an analysis that is easily reproducible,
  it is not enough to write clean code and document it well. One
  must also make sure to list all the dependencies of the analysis
  clearly and ideally provide an easy way to install said dependencies.
  There are several tools that can be used to list dependencies and to
  make them easily installable by someone that wishes to reproduce a study,
  such as [Docker].{proglang}, a containerization solution. This paper will present
  the Nix package manager, and an [R].{proglang} package called [rix]{.pkg} that lowers
  Nix's learning curve for users of the [R].{proglang} programming language.

keywords: [reproducibility, R, Nix]
keywords-formatted: [reproducibility, "[R]{.proglang}", "[Nix]{.proglang}"]

bibliography: bibliography.bib  
---

## Introduction: Reproducibility is also about software {#sec-intro}

@peng2011 introduced the idea of reproducibility being on a continuum: on one of
the ends of this continuum, we only have access to the paper describing the
studies, which is not reproducible at all. Then, if in addition, to this paper
we make the original source code of the analysis that was written to compute the
results of the study available, reproducibility is improved, albeit only by a
little. Adding the original data improves reproducibility yet again. Finally, if
to all this we add what Roger Peng named the *linked and executable code and
data*, we reach the gold standard of full replication.

What is this *linked and executable code and data*? Another way to name this
crucial piece of the reproducibility puzzle is *computational environment*. The
computational environment is all the software required to actually run the
analysis. Here too, we can speak of a continuum. One could simply name and list
the software used: for example, the [R]{.proglang} programming language.
Sometimes, authors have the courtesy to also state the version of [R]{.proglang}
used. Some authors go further, and also list the packages used, and ideally with
their versions as well. Authors rarely state the operating system on which the
analysis was done, even though it has been shown that running the same analysis
with the same software but on different operating systems could lead to different
results, as described in @neupane2019. Authors also only very rarely provide
instructions to install the required tools and software in order to reproduce
their studies.

Tools can be used at each of these steps to reach the gold standard of full
replication. Let's first consider the task of listing the software used.
[R]{.proglang} provides the `sessionInfo()` function whose output can be saved
into a file. Below is an example output of `sessionInfo()`:

```{r, eval = FALSE}
sessionInfo()
```

```
R version 4.3.2 (2023-10-31)
Platform: aarch64-unknown-linux-gnu (64-bit)
Running under: Ubuntu 22.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/aarch64-linux-gnu/openblas-pthread/libblas.so.3 
LAPACK: /usr/lib/aarch64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

time zone: Etc/UTC
tzcode source: system (glibc)

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] nnet_7.3-19  mgcv_1.9-0   nlme_3.1-163

loaded via a namespace (and not attached):
[1] compiler_4.3.2 Matrix_1.6-1.1 tools_4.3.2    splines_4.3.2 
[5] grid_4.3.2     lattice_0.21-9
```

If an author provides this information, other people trying to reproduce the
study (or the author him- or herself in the future) can read this file
and see which version of [R]{.proglang} was used, and which packages (and their
versions) were used as well. However, others would still need to install the
correct software themselves. An alternative to this is instead to use the [renv]{.pkg}
package which generates a so-called `renv.lock` file which also lists
[R]{.proglang} and package versions. Here is an example of such an `renv.lock` file:

```
{
"R": {
  "Version": "4.2.2",
  "Repositories": [
  {
   "Name": "CRAN",
   "URL": "https://packagemanager.rstudio.com/all/latest"
  }
  ]
},
"Packages": {
  "MASS": {
    "Package": "MASS",
    "Version": "7.3-58.1",
    "Source": "Repository",
    "Repository": "CRAN",
    "Hash": "762e1804143a332333c054759f89a706",
    "Requirements": []
  },
  "Matrix": {
    "Package": "Matrix",
    "Version": "1.5-1",
    "Source": "Repository",
    "Repository": "CRAN",
    "Hash": "539dc0c0c05636812f1080f473d2c177",
    "Requirements": [
      "lattice"
    ]

    ***and many more packages***
```

This file lists every package alongside their versions and the repository from
which they were downloaded. Generating this file only requires one to run the
`renv::init()` function. Someone else can then restore the same package library
by running `renv::restore()`. The exact same packages get installed in an
isolated, project-specific, library which doesn't interfere with the other,
main, library of the user. [renv]{.pkg} does not restore the [R]{.proglang}
itself though, so installing the right version of R needs to be handled
separately. Before continuing, it should be noted that other packages exist
which provide similar functionality to [renv]{.pkg}: there is [groundhog]{.pkg}
by @simonsohn2023 which makes it rather easy to install packages as they were
on CRAN at a given date. For example, the code snippet below install the
[purrr]{.pkg} and [ggplot2]{.pkg} packages as they were on April 4th, 2017:

```
groundhog.library("
    library(purrr)
    library(ggplot2)",
    "2017-10-04",
    tolerate.R.version = "4.2.2")
```

These packages also get installed in a project-specfic library so there is no
interferences between these packages and other versions of the same packages
that one might use for other projects. Because [groundhog]{.pkg} does not
install [R]{.proglang} itself, users should either install the required version
themselves, or they should use the `tolerate.R.version` argument as shown in the
example above. Otherwise, [groundhog]{.pkg} would not continue with the
installation of the packages. Another such package, developed by @chan2023 is
[rang]{.pkg}, which also installs packages as they were on a given date.
Yet another way to install packages as they were on a give date is to use
the Posit Package Manager, which provides snapshots of CRAN. For example,
to install the required packages for an analysis as they were on the 30th of June
2023, one could add the following line to the `.Rprofile` file:

```
options(repos = c(REPO_NAME = "https://packagemanager.posit.co/cran/__linux__/jammy/2023-06-30"))
```

The `.Rprofile` file is a file that gets read by R when starting a new session, which
means that every call to the `install.packages()` function will now install the packages
from this snapshotted mirror.

The next step in reaching the gold standard of reproducibility would be to not only
install the right packages used for the analysis, but also the right version of
[R]{.proglang}. Of course, it would be possible to install the right version manually,
but here too, there are tools that simplify the process such as @rlib2023.


There are exceptions of course, a great example of a paper that provides everything
needed to reproduce its results is @mcdermott2021. The author of this paper set up
an accompagnying Github repository to the paper^[https://github.com/grantmcdermott/skeptic-priors]
containing all the instructions to install the required software and then run the
analysis. If we take a closer look at this repository, we will notice that several
tools were used to capture the compatutational environment and make it available to
other researchers:

- The version of [R]{.proglang} was stated;
- Packages and their versions were listed and saved into an `renv.lock` file;
- A `Makefile` was used to run the whole analysis and compile the paper;
- A `Dockerfile` was used to provide the complete computational environment, including the right version of [R]{.proglang} and run the whole analysis easily.

As we go down this list, we get closer to the gold standard of a perfectly
reproducible study.

However, reaching this gold standard is quite costly: one needs to learn a tool
to deal with package versions, then a build automation tool such as
[make]{.proglang} and ideally [Docker]{.proglang} should be added to the list.
[Docker]{.proglang} is a tool that makes it possible to run arbitrary code in a
completely controlled and isolated environment as a way to capture the complete
underlying system libraries. Simply put, a `Dockerfile` provides a complete
description of the computational environment as well as the required instructions
to build the complete project. One can then use [Docker]{.proglang} to build
a so-called *image* which contains all the required software and instructions
to build the project. From this image, it is then possible to run a *container*
which actually runs the analysis.


### Prior art {#subsec-prior}




[R]{.proglang} provides a very flexible implementation of the general GLM framework in the function [glm]{.fct} @ChambersHastie1992 in the [stats]{.pkg} package. Its most important arguments are

```r
glm(formula, data, subset, na.action, weights, offset,
  family = gaussian, start = NULL, control = glm.control(…),
  model = TRUE, y = TRUE, x = FALSE, …)
```

where `formula` plus `data` is the now standard way of specifying regression relationships in [R]{.proglang}/[S]{.proglang} introduced in @ChambersHastie1992. The remaining arguments in the first line (`subset`, `na.action`, `weights`, and `offset`) are also standard for setting up formula-based regression models in [R]{.proglang}/[S]{.proglang}. The arguments in the second line control aspects specific to GLMs while the arguments in the last line specify which components are returned in the fitted model object (of class [glm]{.class} which inherits from [lm]{.class}). For further arguments to [glm]{.fct} (including alternative specifications of starting values) see `?glm`. For estimating a Poisson model `family = poisson` has to be specified.

::: callout
As the synopsis above is a code listing that is not meant to be executed, one can use either the dedicated `{Code}` environment or a simple `{verbatim}` environment for this. Again, spaces before and after should be avoided.

Finally, there might be a reference to a `{table}` such as @tbl-overview. Usually, these are placed at the top of the page (`[t!]`), centered (`\centering`), with a caption below the table, column headers and captions in sentence style, and if possible avoiding vertical lines.
:::

| Type           | Distribution | Method   | Description                                                                                                                                                                                  |
|---------|---------|---------|-----------------------------------------------|
| GLM            | Poisson      | ML       | Poisson regression: classical GLM, estimated by maximum likelihood (ML)                                                                                                                      |
|                |              | Quasi    | "Quasi-Poisson regression'': same mean function, estimated by quasi-ML (QML) or equivalently generalized estimating equations (GEE), inference adjustment via estimated dispersion parameter |
|                |              | Adjusted | "Adjusted Poisson regression'': same mean function, estimated by QML/GEE, inference adjustment via sandwich covariances                                                                      |
|                | NB           | ML       | NB regression: extended GLM, estimated by ML including additional shape parameter                                                                                                            |
| Zero-augmented | Poisson      | ML       | Zero-inflated Poisson (ZIP), hurdle Poisson                                                                                                                                                  |
|                | NB           | ML       | Zero-inflated NB (ZINB), hurdle NB                                                                                                                                                           |
: Overview of various count regression models. The table is usually placed at the top of the page (`[t!]`), centered (`centering`), has a caption below the table, column headers and captions are in sentence style, and if possible vertical lines should be avoided. {#tbl-overview}

## Illustrations {#sec-illustrations}

For a simple illustration of basic Poisson and NB count regression the
`quine` data from the [MASS]{.pkg} package is used. This provides the number
of `Days` that children were absent from school in Australia in a
particular year, along with several covariates that can be employed as regressors. The data can be loaded by

```{R}
#| prompt: true
data(mtcars)
```
and a basic frequency distribution of the response variable is displayed in
@fig-quine.

:::{.callout}
For code input and output, the style files provide dedicated environments.
Either the "agnostic" `{CodeInput}` and `{CodeOutput}` can be used
or, equivalently, the environments `{Sinput}` and `{Soutput}` as
produced by [Sweave]{.fct} or [knitr]{.pkg} when using the `render_sweave()`
hook. Please make sure that all code is properly spaced, e.g., using
`y = a + b * x` and _not_ `y=a+b*x`. Moreover, code input should use "the usual" command prompt in the respective software system. For
[R]{.proglang} code, the prompt `R> ` should be used with `+  ` as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {{< latex >}} text instead. Finally, empty lines before and after code input/output should be avoided (see above).
:::


## Summary and discussion {#sec-summary}

:::{.callout}

As usual…

:::

## Computational details {.unnumbered}

:::{.callout}

If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, …) that are not cited in the main text can be credited here.

:::

The results in this paper were obtained using [R]{.proglang}~3.4.1 with the
[MASS]{.pkg}~7.3.47 package. [R]{.proglang} itself and all packages used are available from the Comprehensive [R]{.proglang} Archive Network (CRAN) at
[https://CRAN.R-project.org/].


## Acknowledgments {.unnumbered}

:::{.callout}

All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).

:::

## References {.unnumbered}

:::{#refs}

:::

{{< pagebreak >}}

## More technical details {#sec-techdetails .unnumbered}

:::{.callout}

Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just _Appendix_).

For more technical style details, please check out JSS's style FAQ at
[https://www.jstatsoft.org/pages/view/style#frequently-asked-questions]
which includes the following topics:

- Title vs. sentence case.
- Graphics formatting.
- Naming conventions.
- Turning JSS manuscripts into [R]{.proglang} package vignettes.
- Trouble shooting.
- Many other potentially helpful details…

:::

## Using BibTeX {#sec-bibtex .unnumbered}

:::{.callout}

References need to be provided in a {{< bibtex >}} file (`.bib`). All
references should be made with `@cite` syntax. This commands yield different
formats of author-year citations and allow to include additional details (e.g.,pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up {{< bibtex >}} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.

- item JSS-specific markup (`\proglang`, `\pkg`, `\code`) should be used in the references.
- item Titles should be in title case.
- item Journal titles should not be abbreviated and in title case.
- item DOIs should be included where available.
- item Software should be properly cited as well. For [R]{.proglang} packages `citation("pkgname")` typically provides a good starting point.

:::


